{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp37-cp37m-macosx_10_14_x86_64.whl (241.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-macosx_10_9_x86_64.whl (979 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.7/979.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from tensorflow) (41.2.0)\n",
      "Requirement already satisfied: packaging in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.49.1-cp37-cp37m-macosx_10_10_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp37-cp37m-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp37-cp37m-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from tensorflow) (4.3.0)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp37-cp37m-macosx_10_9_x86_64.whl (34 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.8/169.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, wheel, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, keras-preprocessing, h5py, grpcio, google-pasta, gast, cachetools, absl-py, requests-oauthlib, markdown, google-auth, astunparse, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.9.24 gast-0.4.0 google-auth-2.12.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.49.1 h5py-3.7.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.1 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 wheel-0.37.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting icrawler\n",
      "  Downloading icrawler-0.6.6-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from icrawler) (1.16.0)\n",
      "Collecting beautifulsoup4>=4.4.1\n",
      "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from icrawler) (9.2.0)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.1-cp37-cp37m-macosx_10_15_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.9.1 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from icrawler) (2.28.1)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from requests>=2.9.1->icrawler) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from requests>=2.9.1->icrawler) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from requests>=2.9.1->icrawler) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages (from requests>=2.9.1->icrawler) (1.26.12)\n",
      "Installing collected packages: soupsieve, lxml, beautifulsoup4, icrawler\n",
      "Successfully installed beautifulsoup4-4.11.1 icrawler-0.6.6 lxml-4.9.1 soupsieve-2.3.2.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install icrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 12:59:15,415 - INFO - icrawler.crawler - start crawling...\n",
      "2022-10-08 12:59:15,420 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2022-10-08 12:59:15,425 - INFO - feeder - thread feeder-001 exit\n",
      "2022-10-08 12:59:15,430 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2022-10-08 12:59:15,439 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
      "2022-10-08 12:59:16,035 - INFO - parser - parsing result page https://www.bing.com/images/async?q=猫&first=0\n",
      "2022-10-08 12:59:16,081 - INFO - downloader - skip downloading file 000001.jpg\n",
      "2022-10-08 12:59:16,083 - INFO - downloader - skip downloading file 000002.jpg\n",
      "2022-10-08 12:59:16,083 - INFO - downloader - skip downloading file 000003.jpg\n",
      "2022-10-08 12:59:16,085 - INFO - downloader - skip downloading file 000004.jpg\n",
      "2022-10-08 12:59:16,086 - INFO - downloader - skip downloading file 000005.jpg\n",
      "2022-10-08 12:59:16,087 - INFO - downloader - skip downloading file 000006.jpg\n",
      "2022-10-08 12:59:16,088 - INFO - downloader - skip downloading file 000007.jpg\n",
      "2022-10-08 12:59:16,089 - INFO - downloader - skip downloading file 000008.jpg\n",
      "2022-10-08 12:59:16,090 - INFO - downloader - skip downloading file 000009.jpg\n",
      "2022-10-08 12:59:16,091 - INFO - downloader - skip downloading file 000010.jpg\n",
      "2022-10-08 12:59:16,092 - INFO - downloader - skip downloading file 000011.jpg\n",
      "2022-10-08 12:59:16,093 - INFO - downloader - skip downloading file 000012.jpg\n",
      "2022-10-08 12:59:16,094 - INFO - downloader - skip downloading file 000013.jpg\n",
      "2022-10-08 12:59:16,095 - INFO - downloader - skip downloading file 000014.jpg\n",
      "2022-10-08 12:59:16,096 - INFO - downloader - skip downloading file 000015.jpg\n",
      "2022-10-08 12:59:16,097 - INFO - downloader - skip downloading file 000016.jpg\n",
      "2022-10-08 12:59:16,097 - INFO - downloader - skip downloading file 000017.jpg\n",
      "2022-10-08 12:59:16,099 - INFO - downloader - skip downloading file 000018.jpg\n",
      "2022-10-08 12:59:16,100 - INFO - downloader - skip downloading file 000019.jpg\n",
      "2022-10-08 12:59:16,102 - INFO - downloader - skip downloading file 000020.jpg\n",
      "2022-10-08 12:59:16,103 - INFO - downloader - skip downloading file 000021.jpg\n",
      "2022-10-08 12:59:16,104 - INFO - downloader - skip downloading file 000022.jpg\n",
      "2022-10-08 12:59:16,105 - INFO - downloader - skip downloading file 000023.jpg\n",
      "2022-10-08 12:59:16,106 - INFO - downloader - skip downloading file 000024.jpg\n",
      "2022-10-08 12:59:16,108 - INFO - downloader - skip downloading file 000025.jpg\n",
      "2022-10-08 12:59:16,109 - INFO - downloader - skip downloading file 000026.jpg\n",
      "2022-10-08 12:59:16,111 - INFO - downloader - skip downloading file 000027.jpg\n",
      "2022-10-08 12:59:16,112 - INFO - downloader - skip downloading file 000028.jpg\n",
      "2022-10-08 12:59:16,113 - INFO - downloader - skip downloading file 000029.jpg\n",
      "2022-10-08 12:59:16,114 - INFO - downloader - skip downloading file 000030.jpg\n",
      "2022-10-08 12:59:16,118 - INFO - downloader - skip downloading file 000031.jpg\n",
      "2022-10-08 12:59:16,120 - INFO - downloader - skip downloading file 000032.jpg\n",
      "2022-10-08 12:59:16,122 - INFO - downloader - skip downloading file 000033.jpg\n",
      "2022-10-08 12:59:16,124 - INFO - downloader - skip downloading file 000034.jpg\n",
      "2022-10-08 12:59:16,125 - INFO - downloader - skip downloading file 000035.jpg\n",
      "2022-10-08 12:59:16,334 - INFO - parser - parsing result page https://www.bing.com/images/async?q=猫&first=20\n",
      "2022-10-08 12:59:16,364 - INFO - downloader - skip downloading file 000036.jpg\n",
      "2022-10-08 12:59:16,365 - INFO - downloader - skip downloading file 000037.jpg\n",
      "2022-10-08 12:59:16,367 - INFO - downloader - skip downloading file 000038.jpg\n",
      "2022-10-08 12:59:16,368 - INFO - downloader - skip downloading file 000039.jpg\n",
      "2022-10-08 12:59:16,369 - INFO - downloader - skip downloading file 000040.jpg\n",
      "2022-10-08 12:59:16,370 - INFO - downloader - skip downloading file 000041.jpg\n",
      "2022-10-08 12:59:16,371 - INFO - downloader - skip downloading file 000042.jpg\n",
      "2022-10-08 12:59:16,372 - INFO - downloader - skip downloading file 000043.jpg\n",
      "2022-10-08 12:59:16,373 - INFO - downloader - skip downloading file 000044.jpg\n",
      "2022-10-08 12:59:16,375 - INFO - downloader - skip downloading file 000045.jpg\n",
      "2022-10-08 12:59:16,376 - INFO - downloader - skip downloading file 000046.jpg\n",
      "2022-10-08 12:59:16,377 - INFO - downloader - skip downloading file 000047.jpg\n",
      "2022-10-08 12:59:16,378 - INFO - downloader - skip downloading file 000048.jpg\n",
      "2022-10-08 12:59:16,380 - INFO - downloader - skip downloading file 000049.jpg\n",
      "2022-10-08 12:59:16,382 - INFO - downloader - skip downloading file 000050.jpg\n",
      "2022-10-08 12:59:16,384 - INFO - downloader - skip downloading file 000051.jpg\n",
      "2022-10-08 12:59:16,385 - INFO - downloader - skip downloading file 000052.jpg\n",
      "2022-10-08 12:59:16,386 - INFO - downloader - skip downloading file 000053.jpg\n",
      "2022-10-08 12:59:16,387 - INFO - downloader - skip downloading file 000054.jpg\n",
      "2022-10-08 12:59:16,601 - INFO - parser - parsing result page https://www.bing.com/images/async?q=猫&first=40\n",
      "2022-10-08 12:59:16,641 - INFO - downloader - skip downloading file 000055.jpg\n",
      "2022-10-08 12:59:16,676 - INFO - downloader - skip downloading file 000056.jpg\n",
      "2022-10-08 12:59:16,679 - INFO - downloader - skip downloading file 000057.jpg\n",
      "2022-10-08 12:59:16,679 - INFO - downloader - skip downloading file 000058.jpg\n",
      "2022-10-08 12:59:16,681 - INFO - downloader - skip downloading file 000059.jpg\n",
      "2022-10-08 12:59:16,682 - INFO - downloader - skip downloading file 000060.jpg\n",
      "2022-10-08 12:59:16,683 - INFO - downloader - skip downloading file 000061.jpg\n",
      "2022-10-08 12:59:16,685 - INFO - downloader - skip downloading file 000062.jpg\n",
      "2022-10-08 12:59:16,702 - INFO - downloader - skip downloading file 000063.jpg\n",
      "2022-10-08 12:59:16,703 - INFO - downloader - skip downloading file 000064.jpg\n",
      "2022-10-08 12:59:16,705 - INFO - downloader - skip downloading file 000065.jpg\n",
      "2022-10-08 12:59:16,706 - INFO - downloader - skip downloading file 000066.jpg\n",
      "2022-10-08 12:59:16,707 - INFO - downloader - skip downloading file 000067.jpg\n",
      "2022-10-08 12:59:16,709 - INFO - downloader - skip downloading file 000068.jpg\n",
      "2022-10-08 12:59:16,710 - INFO - downloader - skip downloading file 000069.jpg\n",
      "2022-10-08 12:59:16,712 - INFO - downloader - skip downloading file 000070.jpg\n",
      "2022-10-08 12:59:16,714 - INFO - downloader - skip downloading file 000071.jpg\n",
      "2022-10-08 12:59:16,715 - INFO - downloader - skip downloading file 000072.jpg\n",
      "2022-10-08 12:59:16,716 - INFO - downloader - skip downloading file 000073.jpg\n",
      "2022-10-08 12:59:16,717 - INFO - downloader - skip downloading file 000074.jpg\n",
      "2022-10-08 12:59:16,945 - INFO - parser - parsing result page https://www.bing.com/images/async?q=猫&first=60\n",
      "2022-10-08 12:59:16,966 - INFO - downloader - skip downloading file 000075.jpg\n",
      "2022-10-08 12:59:16,968 - INFO - downloader - skip downloading file 000076.jpg\n",
      "2022-10-08 12:59:16,969 - INFO - downloader - skip downloading file 000077.jpg\n",
      "2022-10-08 12:59:16,971 - INFO - downloader - skip downloading file 000078.jpg\n",
      "2022-10-08 12:59:16,972 - INFO - downloader - skip downloading file 000079.jpg\n",
      "2022-10-08 12:59:16,973 - INFO - downloader - skip downloading file 000080.jpg\n",
      "2022-10-08 12:59:16,974 - INFO - downloader - skip downloading file 000081.jpg\n",
      "2022-10-08 12:59:16,975 - INFO - downloader - skip downloading file 000082.jpg\n",
      "2022-10-08 12:59:16,976 - INFO - downloader - skip downloading file 000083.jpg\n",
      "2022-10-08 12:59:16,977 - INFO - downloader - skip downloading file 000084.jpg\n",
      "2022-10-08 12:59:16,978 - INFO - downloader - skip downloading file 000085.jpg\n",
      "2022-10-08 12:59:16,979 - INFO - downloader - skip downloading file 000086.jpg\n",
      "2022-10-08 12:59:16,980 - INFO - downloader - skip downloading file 000087.jpg\n",
      "2022-10-08 12:59:16,981 - INFO - downloader - skip downloading file 000088.jpg\n",
      "2022-10-08 12:59:16,982 - INFO - downloader - skip downloading file 000089.jpg\n",
      "2022-10-08 12:59:16,983 - INFO - downloader - skip downloading file 000090.jpg\n",
      "2022-10-08 12:59:16,984 - INFO - downloader - skip downloading file 000091.jpg\n",
      "2022-10-08 12:59:16,985 - INFO - downloader - skip downloading file 000092.jpg\n",
      "2022-10-08 12:59:17,211 - INFO - parser - parsing result page https://www.bing.com/images/async?q=猫&first=80\n",
      "2022-10-08 12:59:17,238 - INFO - downloader - skip downloading file 000093.jpg\n",
      "2022-10-08 12:59:17,238 - INFO - downloader - skip downloading file 000094.jpg\n",
      "2022-10-08 12:59:17,239 - INFO - downloader - skip downloading file 000095.jpg\n",
      "2022-10-08 12:59:17,240 - INFO - downloader - skip downloading file 000096.jpg\n",
      "2022-10-08 12:59:17,241 - INFO - downloader - skip downloading file 000097.jpg\n",
      "2022-10-08 12:59:17,242 - INFO - downloader - skip downloading file 000098.jpg\n",
      "2022-10-08 12:59:17,244 - INFO - downloader - skip downloading file 000099.jpg\n",
      "2022-10-08 12:59:17,244 - INFO - downloader - skip downloading file 000100.jpg\n",
      "2022-10-08 12:59:17,466 - INFO - downloader - downloaded images reach max num, thread downloader-001 is ready to exit\n",
      "2022-10-08 12:59:17,467 - INFO - downloader - thread downloader-001 exit\n",
      "2022-10-08 12:59:18,457 - INFO - icrawler.crawler - Crawling task done!\n",
      "2022-10-08 12:59:18,459 - INFO - icrawler.crawler - start crawling...\n",
      "2022-10-08 12:59:18,463 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2022-10-08 12:59:18,464 - INFO - feeder - thread feeder-001 exit\n",
      "2022-10-08 12:59:18,465 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2022-10-08 12:59:18,467 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
      "2022-10-08 12:59:18,917 - INFO - parser - parsing result page https://www.bing.com/images/async?q=犬&first=0\n",
      "2022-10-08 12:59:18,989 - INFO - downloader - skip downloading file 000001.jpg\n",
      "2022-10-08 12:59:18,992 - INFO - downloader - skip downloading file 000002.jpg\n",
      "2022-10-08 12:59:18,992 - INFO - downloader - skip downloading file 000003.jpg\n",
      "2022-10-08 12:59:18,994 - INFO - downloader - skip downloading file 000004.jpg\n",
      "2022-10-08 12:59:18,995 - INFO - downloader - skip downloading file 000005.jpg\n",
      "2022-10-08 12:59:18,997 - INFO - downloader - skip downloading file 000006.jpg\n",
      "2022-10-08 12:59:19,008 - INFO - downloader - skip downloading file 000007.jpg\n",
      "2022-10-08 12:59:19,015 - INFO - downloader - skip downloading file 000008.jpg\n",
      "2022-10-08 12:59:19,016 - INFO - downloader - skip downloading file 000009.jpg\n",
      "2022-10-08 12:59:19,017 - INFO - downloader - skip downloading file 000010.jpg\n",
      "2022-10-08 12:59:19,018 - INFO - downloader - skip downloading file 000011.jpg\n",
      "2022-10-08 12:59:19,019 - INFO - downloader - skip downloading file 000012.jpg\n",
      "2022-10-08 12:59:19,022 - INFO - downloader - skip downloading file 000013.jpg\n",
      "2022-10-08 12:59:19,023 - INFO - downloader - skip downloading file 000014.jpg\n",
      "2022-10-08 12:59:19,025 - INFO - downloader - skip downloading file 000015.jpg\n",
      "2022-10-08 12:59:19,026 - INFO - downloader - skip downloading file 000016.jpg\n",
      "2022-10-08 12:59:19,028 - INFO - downloader - skip downloading file 000017.jpg\n",
      "2022-10-08 12:59:19,030 - INFO - downloader - skip downloading file 000018.jpg\n",
      "2022-10-08 12:59:19,031 - INFO - downloader - skip downloading file 000019.jpg\n",
      "2022-10-08 12:59:19,033 - INFO - downloader - skip downloading file 000020.jpg\n",
      "2022-10-08 12:59:19,034 - INFO - downloader - skip downloading file 000021.jpg\n",
      "2022-10-08 12:59:19,035 - INFO - downloader - skip downloading file 000022.jpg\n",
      "2022-10-08 12:59:19,037 - INFO - downloader - skip downloading file 000023.jpg\n",
      "2022-10-08 12:59:19,039 - INFO - downloader - skip downloading file 000024.jpg\n",
      "2022-10-08 12:59:19,041 - INFO - downloader - skip downloading file 000025.jpg\n",
      "2022-10-08 12:59:19,042 - INFO - downloader - skip downloading file 000026.jpg\n",
      "2022-10-08 12:59:19,043 - INFO - downloader - skip downloading file 000027.jpg\n",
      "2022-10-08 12:59:19,045 - INFO - downloader - skip downloading file 000028.jpg\n",
      "2022-10-08 12:59:19,048 - INFO - downloader - skip downloading file 000029.jpg\n",
      "2022-10-08 12:59:19,049 - INFO - downloader - skip downloading file 000030.jpg\n",
      "2022-10-08 12:59:19,051 - INFO - downloader - skip downloading file 000031.jpg\n",
      "2022-10-08 12:59:19,053 - INFO - downloader - skip downloading file 000032.jpg\n",
      "2022-10-08 12:59:19,257 - INFO - parser - downloaded image reached max num, thread parser-001 is ready to exit\n",
      "2022-10-08 12:59:19,258 - INFO - parser - thread parser-001 exit\n",
      "2022-10-08 12:59:19,321 - INFO - parser - parsing result page https://www.bing.com/images/async?q=犬&first=20\n",
      "2022-10-08 12:59:19,361 - INFO - downloader - skip downloading file 000033.jpg\n",
      "2022-10-08 12:59:19,363 - INFO - downloader - skip downloading file 000034.jpg\n",
      "2022-10-08 12:59:19,365 - INFO - downloader - skip downloading file 000035.jpg\n",
      "2022-10-08 12:59:19,366 - INFO - downloader - skip downloading file 000036.jpg\n",
      "2022-10-08 12:59:19,368 - INFO - downloader - skip downloading file 000037.jpg\n",
      "2022-10-08 12:59:19,371 - INFO - downloader - skip downloading file 000038.jpg\n",
      "2022-10-08 12:59:19,372 - INFO - downloader - skip downloading file 000039.jpg\n",
      "2022-10-08 12:59:19,374 - INFO - downloader - skip downloading file 000040.jpg\n",
      "2022-10-08 12:59:19,375 - INFO - downloader - skip downloading file 000041.jpg\n",
      "2022-10-08 12:59:19,377 - INFO - downloader - skip downloading file 000042.jpg\n",
      "2022-10-08 12:59:19,379 - INFO - downloader - skip downloading file 000043.jpg\n",
      "2022-10-08 12:59:19,382 - INFO - downloader - skip downloading file 000044.jpg\n",
      "2022-10-08 12:59:19,392 - INFO - downloader - skip downloading file 000045.jpg\n",
      "2022-10-08 12:59:19,399 - INFO - downloader - skip downloading file 000046.jpg\n",
      "2022-10-08 12:59:19,411 - INFO - downloader - skip downloading file 000047.jpg\n",
      "2022-10-08 12:59:19,413 - INFO - downloader - skip downloading file 000048.jpg\n",
      "2022-10-08 12:59:19,415 - INFO - downloader - skip downloading file 000049.jpg\n",
      "2022-10-08 12:59:19,638 - INFO - parser - parsing result page https://www.bing.com/images/async?q=犬&first=40\n",
      "2022-10-08 12:59:19,666 - INFO - downloader - skip downloading file 000050.jpg\n",
      "2022-10-08 12:59:19,667 - INFO - downloader - skip downloading file 000051.jpg\n",
      "2022-10-08 12:59:19,668 - INFO - downloader - skip downloading file 000052.jpg\n",
      "2022-10-08 12:59:19,669 - INFO - downloader - skip downloading file 000053.jpg\n",
      "2022-10-08 12:59:19,670 - INFO - downloader - skip downloading file 000054.jpg\n",
      "2022-10-08 12:59:19,671 - INFO - downloader - skip downloading file 000055.jpg\n",
      "2022-10-08 12:59:19,672 - INFO - downloader - skip downloading file 000056.jpg\n",
      "2022-10-08 12:59:19,673 - INFO - downloader - skip downloading file 000057.jpg\n",
      "2022-10-08 12:59:19,674 - INFO - downloader - skip downloading file 000058.jpg\n",
      "2022-10-08 12:59:19,675 - INFO - downloader - skip downloading file 000059.jpg\n",
      "2022-10-08 12:59:19,676 - INFO - downloader - skip downloading file 000060.jpg\n",
      "2022-10-08 12:59:19,677 - INFO - downloader - skip downloading file 000061.jpg\n",
      "2022-10-08 12:59:19,678 - INFO - downloader - skip downloading file 000062.jpg\n",
      "2022-10-08 12:59:19,680 - INFO - downloader - skip downloading file 000063.jpg\n",
      "2022-10-08 12:59:19,682 - INFO - downloader - skip downloading file 000064.jpg\n",
      "2022-10-08 12:59:19,683 - INFO - downloader - skip downloading file 000065.jpg\n",
      "2022-10-08 12:59:19,684 - INFO - downloader - skip downloading file 000066.jpg\n",
      "2022-10-08 12:59:19,687 - INFO - downloader - skip downloading file 000067.jpg\n",
      "2022-10-08 12:59:19,911 - INFO - parser - parsing result page https://www.bing.com/images/async?q=犬&first=60\n",
      "2022-10-08 12:59:19,937 - INFO - downloader - skip downloading file 000068.jpg\n",
      "2022-10-08 12:59:19,938 - INFO - downloader - skip downloading file 000069.jpg\n",
      "2022-10-08 12:59:19,939 - INFO - downloader - skip downloading file 000070.jpg\n",
      "2022-10-08 12:59:19,940 - INFO - downloader - skip downloading file 000071.jpg\n",
      "2022-10-08 12:59:19,941 - INFO - downloader - skip downloading file 000072.jpg\n",
      "2022-10-08 12:59:19,942 - INFO - downloader - skip downloading file 000073.jpg\n",
      "2022-10-08 12:59:19,943 - INFO - downloader - skip downloading file 000074.jpg\n",
      "2022-10-08 12:59:19,944 - INFO - downloader - skip downloading file 000075.jpg\n",
      "2022-10-08 12:59:19,946 - INFO - downloader - skip downloading file 000076.jpg\n",
      "2022-10-08 12:59:19,947 - INFO - downloader - skip downloading file 000077.jpg\n",
      "2022-10-08 12:59:19,947 - INFO - downloader - skip downloading file 000078.jpg\n",
      "2022-10-08 12:59:19,949 - INFO - downloader - skip downloading file 000079.jpg\n",
      "2022-10-08 12:59:19,951 - INFO - downloader - skip downloading file 000080.jpg\n",
      "2022-10-08 12:59:19,952 - INFO - downloader - skip downloading file 000081.jpg\n",
      "2022-10-08 12:59:19,955 - INFO - downloader - skip downloading file 000082.jpg\n",
      "2022-10-08 12:59:19,956 - INFO - downloader - skip downloading file 000083.jpg\n",
      "2022-10-08 12:59:19,957 - INFO - downloader - skip downloading file 000084.jpg\n",
      "2022-10-08 12:59:20,201 - INFO - parser - parsing result page https://www.bing.com/images/async?q=犬&first=80\n",
      "2022-10-08 12:59:20,228 - INFO - downloader - skip downloading file 000085.jpg\n",
      "2022-10-08 12:59:20,229 - INFO - downloader - skip downloading file 000086.jpg\n",
      "2022-10-08 12:59:20,230 - INFO - downloader - skip downloading file 000087.jpg\n",
      "2022-10-08 12:59:20,231 - INFO - downloader - skip downloading file 000088.jpg\n",
      "2022-10-08 12:59:20,232 - INFO - downloader - skip downloading file 000089.jpg\n",
      "2022-10-08 12:59:20,233 - INFO - downloader - skip downloading file 000090.jpg\n",
      "2022-10-08 12:59:20,234 - INFO - downloader - skip downloading file 000091.jpg\n",
      "2022-10-08 12:59:20,235 - INFO - downloader - skip downloading file 000092.jpg\n",
      "2022-10-08 12:59:20,237 - INFO - downloader - skip downloading file 000093.jpg\n",
      "2022-10-08 12:59:20,239 - INFO - downloader - skip downloading file 000094.jpg\n",
      "2022-10-08 12:59:20,239 - INFO - downloader - skip downloading file 000095.jpg\n",
      "2022-10-08 12:59:20,240 - INFO - downloader - skip downloading file 000096.jpg\n",
      "2022-10-08 12:59:20,241 - INFO - downloader - skip downloading file 000097.jpg\n",
      "2022-10-08 12:59:20,241 - INFO - downloader - skip downloading file 000098.jpg\n",
      "2022-10-08 12:59:20,242 - INFO - downloader - skip downloading file 000099.jpg\n",
      "2022-10-08 12:59:22,244 - INFO - parser - no more page urls for thread parser-001 to parse\n",
      "2022-10-08 12:59:22,245 - INFO - parser - thread parser-001 exit\n",
      "2022-10-08 12:59:25,250 - INFO - downloader - no more download task for thread downloader-001\n",
      "2022-10-08 12:59:25,252 - INFO - downloader - thread downloader-001 exit\n",
      "2022-10-08 12:59:25,501 - INFO - icrawler.crawler - Crawling task done!\n",
      "/Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages/ipykernel_launcher.py:48: DeprecationWarning: FLIP_LEFT_RIGHT is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_LEFT_RIGHT instead.\n",
      "/Users/kaiyuyokoi/.pyenv/versions/3.7.5/lib/python3.7/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 64, 64, 3)\n",
      "Epoch 1/40\n",
      "86/86 [==============================] - 15s 168ms/step - loss: 0.6724 - accuracy: 0.5838\n",
      "Epoch 2/40\n",
      "86/86 [==============================] - 14s 162ms/step - loss: 0.5987 - accuracy: 0.6833\n",
      "Epoch 3/40\n",
      "86/86 [==============================] - 14s 168ms/step - loss: 0.5418 - accuracy: 0.7150\n",
      "Epoch 4/40\n",
      "86/86 [==============================] - 18s 205ms/step - loss: 0.5000 - accuracy: 0.7521\n",
      "Epoch 5/40\n",
      "86/86 [==============================] - 16s 186ms/step - loss: 0.4598 - accuracy: 0.7729\n",
      "Epoch 6/40\n",
      "86/86 [==============================] - 17s 201ms/step - loss: 0.4294 - accuracy: 0.7950\n",
      "Epoch 7/40\n",
      "86/86 [==============================] - 15s 180ms/step - loss: 0.3843 - accuracy: 0.8321\n",
      "Epoch 8/40\n",
      "86/86 [==============================] - 14s 161ms/step - loss: 0.3415 - accuracy: 0.8571\n",
      "Epoch 9/40\n",
      "86/86 [==============================] - 14s 161ms/step - loss: 0.3002 - accuracy: 0.8813\n",
      "Epoch 10/40\n",
      "86/86 [==============================] - 14s 165ms/step - loss: 0.2810 - accuracy: 0.8792\n",
      "Epoch 11/40\n",
      "86/86 [==============================] - 14s 166ms/step - loss: 0.2440 - accuracy: 0.9075\n",
      "Epoch 12/40\n",
      "86/86 [==============================] - 14s 165ms/step - loss: 0.2211 - accuracy: 0.9137\n",
      "Epoch 13/40\n",
      "86/86 [==============================] - 14s 162ms/step - loss: 0.1993 - accuracy: 0.9204\n",
      "Epoch 14/40\n",
      "86/86 [==============================] - 15s 180ms/step - loss: 0.1748 - accuracy: 0.9358\n",
      "Epoch 15/40\n",
      "86/86 [==============================] - 14s 168ms/step - loss: 0.1641 - accuracy: 0.9362\n",
      "Epoch 16/40\n",
      "86/86 [==============================] - 14s 162ms/step - loss: 0.1394 - accuracy: 0.9529\n",
      "Epoch 17/40\n",
      "86/86 [==============================] - 14s 164ms/step - loss: 0.1244 - accuracy: 0.9550\n",
      "Epoch 18/40\n",
      "86/86 [==============================] - 14s 163ms/step - loss: 0.1145 - accuracy: 0.9621\n",
      "Epoch 19/40\n",
      "86/86 [==============================] - 14s 165ms/step - loss: 0.1012 - accuracy: 0.9658\n",
      "Epoch 20/40\n",
      "86/86 [==============================] - 14s 160ms/step - loss: 0.0893 - accuracy: 0.9729\n",
      "Epoch 21/40\n",
      "86/86 [==============================] - 14s 159ms/step - loss: 0.0842 - accuracy: 0.9725\n",
      "Epoch 22/40\n",
      "86/86 [==============================] - 14s 164ms/step - loss: 0.0719 - accuracy: 0.9775\n",
      "Epoch 23/40\n",
      "86/86 [==============================] - 14s 165ms/step - loss: 0.0564 - accuracy: 0.9871\n",
      "Epoch 24/40\n",
      "86/86 [==============================] - 14s 163ms/step - loss: 0.0548 - accuracy: 0.9837\n",
      "Epoch 25/40\n",
      "86/86 [==============================] - 14s 162ms/step - loss: 0.0487 - accuracy: 0.9871\n",
      "Epoch 26/40\n",
      "86/86 [==============================] - 14s 167ms/step - loss: 0.0426 - accuracy: 0.9879\n",
      "Epoch 27/40\n",
      "86/86 [==============================] - 14s 165ms/step - loss: 0.0353 - accuracy: 0.9917\n",
      "Epoch 28/40\n",
      "86/86 [==============================] - 14s 163ms/step - loss: 0.0309 - accuracy: 0.9900\n",
      "Epoch 29/40\n",
      "86/86 [==============================] - 14s 164ms/step - loss: 0.0308 - accuracy: 0.9900\n",
      "Epoch 30/40\n",
      "86/86 [==============================] - 14s 166ms/step - loss: 0.0258 - accuracy: 0.9904\n",
      "Epoch 31/40\n",
      "86/86 [==============================] - 20s 231ms/step - loss: 0.0268 - accuracy: 0.9908\n",
      "Epoch 32/40\n",
      "86/86 [==============================] - 16s 185ms/step - loss: 0.0228 - accuracy: 0.9925\n",
      "Epoch 33/40\n",
      "86/86 [==============================] - 14s 164ms/step - loss: 0.0165 - accuracy: 0.9954\n",
      "Epoch 34/40\n",
      "86/86 [==============================] - 14s 164ms/step - loss: 0.0155 - accuracy: 0.9967\n",
      "Epoch 35/40\n",
      "86/86 [==============================] - 15s 175ms/step - loss: 0.0181 - accuracy: 0.9929\n",
      "Epoch 36/40\n",
      "86/86 [==============================] - 14s 164ms/step - loss: 0.0121 - accuracy: 0.9971\n",
      "Epoch 37/40\n",
      "86/86 [==============================] - 14s 163ms/step - loss: 0.0130 - accuracy: 0.9954\n",
      "Epoch 38/40\n",
      "86/86 [==============================] - 14s 164ms/step - loss: 0.0081 - accuracy: 0.9987\n",
      "Epoch 39/40\n",
      "86/86 [==============================] - 14s 164ms/step - loss: 0.0090 - accuracy: 0.9983\n",
      "Epoch 40/40\n",
      "86/86 [==============================] - 15s 178ms/step - loss: 0.0101 - accuracy: 0.9971\n",
      "we finished training classification model\n"
     ]
    }
   ],
   "source": [
    "from icrawler.builtin import BingImageCrawler\n",
    "\n",
    "# 猫の画像を100枚取得\n",
    "crawler = BingImageCrawler(storage={\"root_dir\": \"cat\"})\n",
    "crawler.crawl(keyword=\"猫\", max_num=100)\n",
    "\n",
    "from icrawler.builtin import BingImageCrawler\n",
    "\n",
    "# 犬の画像を100枚取得\n",
    "crawler = BingImageCrawler(storage={\"root_dir\": \"dog\"})\n",
    "crawler.crawl(keyword=\"犬\", max_num=100)\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "# IOError: image file is truncated (0 bytes not processed)回避のため\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "classes = [\"dog\", \"cat\"]\n",
    "num_classes = len(classes)\n",
    "image_size = 64\n",
    "num_testdata = 25\n",
    "\n",
    "X_train = []\n",
    "X_test  = []\n",
    "y_train = []\n",
    "y_test  = []\n",
    "\n",
    "for index, classlabel in enumerate(classes):\n",
    "    photos_dir = \"./\" + classlabel\n",
    "    files = glob.glob(photos_dir + \"/*.jpg\")\n",
    "    for i, file in enumerate(files):\n",
    "        image = Image.open(file)\n",
    "        image = image.convert(\"RGB\")\n",
    "        image = image.resize((image_size, image_size))\n",
    "        data = np.asarray(image)\n",
    "        if i < num_testdata:\n",
    "            X_test.append(data)\n",
    "            y_test.append(index)\n",
    "        else:\n",
    "            for angle in range(-20, 20, 5):\n",
    "\n",
    "                img_r = image.rotate(angle)\n",
    "                data = np.asarray(img_r)\n",
    "                X_train.append(data)\n",
    "                y_train.append(index)\n",
    "                # FLIP_LEFT_RIGHT　は 左右反転\n",
    "                img_trains = img_r.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                data = np.asarray(img_trains)\n",
    "                X_train.append(data)\n",
    "                y_train.append(index)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test  = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test  = np.array(y_test)\n",
    "\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"./dog_cat.npy\", xy)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "classes = [\"dog\", \"cat\"]\n",
    "num_classes = len(classes)\n",
    "image_size = 64\n",
    "print(X_train.shape)\n",
    "\n",
    "def load_data():\n",
    "    X_train, X_test, y_train, y_test = np.load(\"./dog_cat.npy\", allow_pickle=True)\n",
    "    # 入力データの各画素値を0-1の範囲で正規化(学習コストを下げるため)\n",
    "    X_train = X_train.astype(\"float\") / 255\n",
    "    X_test  = X_test.astype(\"float\") / 255\n",
    "    # to_categorical()にてラベルをone hot vector化\n",
    "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test  = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def train(X, y, X_test, y_test):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32,(3,3), padding='same',input_shape=X.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(64,(3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64,(3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.45))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    opt = optimizers.RMSprop(lr=0.00005, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "    model.fit(X, y, batch_size=28, epochs=40)\n",
    "    # HDF5ファイルにKerasのモデルを保存\n",
    "    model.save('./cnn.h5')\n",
    "\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    # データの読み込み\n",
    "    X_train, y_train, X_test, y_test = load_data()\n",
    "\n",
    "    # モデルの学習\n",
    "    model = train(X_train, y_train, X_test, y_test)\n",
    "\n",
    "main()\n",
    "print(\"we finished training classification model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('3.7.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45f9bbb8f7e3f8933580a9410ed22931a9936ba280be7945dbe18565235e9906"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
